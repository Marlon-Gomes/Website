\documentclass[11pt]{amsart}
%%%%%%%%%%%%%% Packages
\usepackage{amssymb,amsfonts,amsthm,amsmath}
\usepackage[english]{babel}
\usepackage[all,cmtip]{xy}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{tensor}
\usepackage{csquotes}
\usepackage[vcentermath]{youngtab}
%\usepackage{stix}
\usetikzlibrary{arrows,chains,matrix,positioning,scopes}
%\usepackage{mathrsfs}
%\usepackage[notcite,notref]{showkeys}


%%%%%%%%%%% Tikz
\makeatletter
\tikzset{join/.code=\tikzset{after node path={%
\ifx\tikzchainprevious\pgfutil@empty\else(\tikzchainprevious)%
edge[every join]#1(\tikzchaincurrent)\fi}}}
\makeatother
\tikzset{>=stealth',every on chain/.append style={join},
         every join/.style={->}}

        

%%%%%%%%%%%% Personalized commands and environments

\newcommand{\inputc}[1]{ \raisebox{-0.5\height}{\input{#1}} }
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}{Example}
%\newtheorem{theorem*}{Theorem}

\newcommand{\func}[3]{{#1} : {#2} \longrightarrow {#3}}
\numberwithin{equation}{section}
\newcommand{\dbar}{\bar{\partial}}
\newenvironment{myproof}{\noindent{it Proof}
\setlength{\parindent}{0mm}}
{$\hfill \bs$}


%%%%%%%%%%%%%%%%%%%%%%%% Title and Author information

\title{MAT 303 Recitations: Week 14}


\author[M. Gomes]{Marlon de Oliveira Gomes}
\address{Mathematics Department 3-101, Stony Brook University,
100 Nicolls Road, Math Tower, 
Stony Brook, NY, 11794, USA} \email{mgomes@math.stonybrook.edu}



%%%%%%%%%%% Text
\begin{document}

\maketitle


\section*{Section 5.1: Matrices and Linear Systems}

This section is mostly a review of linear algebra. We will take for granted the basic algebraic operations of sum, multiplication by scalar, and matrix multiplication, which you can review by solving the first few problems in this section. 

\begin{example}
This example is extracted from problem 5.1.17 in our textbook. Consider the first-order system
\begin{align*}
x'(t) & = 3x - 4y + z + t \\
y'(t) & = x - 3z  + t^2 \\
z'(t) & = 6y -7z + t^3.
\end{align*}
You are tasked with writing this system in vector form, 
\begin{equation*}
\mathbf{x}'(t)=P(t)\mathbf{x}(t) + \mathbf{f}(t).
\end{equation*}
The column-vectors $\mathbf{x}$ and $\mathbf{f}$ are 
\begin{equation*}
\mathbf{x}=\left(\begin{matrix}
x \\
y \\
z
\end{matrix}
\right) \ \mbox{and} \ \mathbf{f}(t) = \left(
\begin{matrix}
t \\
t^2\\
t^3,
\end{matrix}
\right),
\end{equation*}
while the coefficient matrix $P$ is 
\begin{equation*}
P(t) = 
\left(
	\begin{matrix}
		3 & -4 & 1 \\
		1 & 0 & 3 \\
		0 & 6 & -7
	\end{matrix}
\right).
\end{equation*}
Here we note that while $P$ is a constant matrix in this example, it could depend on time in other problems in this section.
\end{example}

Next we recall the Wronskian of a collection of solutions to a first-order system. Consider a linear system
\begin{equation*}
\mathbf{x}^{'}(t)=P(t) x(t),
\end{equation*}
where $P$ is an $n \times n$ matrix, and \emph{assume} that $\mathbf{x}_1(t), \cdots, \mathbf{x}_n(t)$ is a collection of solutions ( $n \times 1$ column-vectors). The Wronskian of the set of solutions is the determinant of the $n \times n$ matrix assembled by juxtaposing the column vectors,
\begin{equation*}
W(\mathbf{x}_1, \cdots , \mathbf{x}_n) = \left(
\begin{matrix}
\mathbf{x}_1 & \cdots & \mathbf{x}_n
\end{matrix}
\right)
\end{equation*}
The Wronskian Criterion states that if the coefficient-matrix is continuous, then the following alternatives hold:
\begin{itemize}
\item the determinant of this matrix is nowhere-zero, in which case the solutions are linearly independent;
\item the determinant of this matrix is identically zero, in which case the solutions are linearly dependent. 
\end{itemize}
Let's see these ideas in practice in problem 5.2.23 below. 

\begin{example}
Consider the system of differential equations
\begin{align*}
\mathbf{x}' = \left( 
\begin{matrix}
3 & -1 \\
5 & -3
\end{matrix}
\right) x. 
\end{align*}
In this problem we are asked to verify that the column vectors 
\begin{equation*}
\mathbf{x}_1=\left(
\begin{matrix}
e^{2t}\\
e^{2t}
\end{matrix}
\right), \ \ \mathbf{x}_2=\left(
\begin{matrix}
e^{-2t}\\
5e^{-2t}
\end{matrix}
\right)
\end{equation*}
are linearly independent solutions to the differential equation. 

First we verify that $\mathbf{x}_1$ and $\mathbf{x}_2$ solve the system by direct computation, 
\begin{align*}
\left(
\begin{matrix}
3 & -1 \\
5 & -3
\end{matrix}
\right)
\left(
\begin{matrix}
e^{2t}\\
e^{2t}
\end{matrix}
\right) & = \left(
\begin{matrix}
3e^{2t}-e^{2t}\\
5e^{2t}-3e^{2t}
\end{matrix}
\right) \\
& = \left(
\begin{matrix}
2e^{2t}\\
2e^{2t}
\end{matrix}
\right) \\
&= \mathbf{x}_{1}^{'},
\end{align*}
while
\begin{align*}
\left(
\begin{matrix}
3 & -1 \\
5 & -3
\end{matrix}
\right)
\left(
\begin{matrix}
e^{-2t}\\
5e^{-2t}
\end{matrix}
\right) & = \left(
\begin{matrix}
3e^{-2t}-5e^{-2t}\\
5e^{-2t}-15e^{-2t}
\end{matrix}
\right) \\
& = \left(
\begin{matrix}
-2e^{-2t}\\
-10e^{-2t}
\end{matrix}
\right) \\
&= \mathbf{x}_{2}^{'},
\end{align*}
as desired. Next we compute the Wronskian
\begin{equation*}
W(\mathbf{x}_1, \mathbf{x}_2) = \det \left(
\begin{matrix}
e^{2t} & e^{-2t}\\
e^{2t} & 5e^{-2t}
\end{matrix}
\right) = 5e^{2t}e^{-2t}-e^{2t}e^{-2t}=4,
\end{equation*}
thus showing that the solutions are linearly independent. A general solution to the problem may be expressed as a linear combination of $\mathbf{x}_1$ and $\mathbf{x}_2$,
\begin{equation*}
x(t) = C_1\left(
\begin{matrix}
e^{2t} \\
e^{2t}
\end{matrix}
\right) + C_2\left(
\begin{matrix}
e^{-2t}\\
5e^{-2t}
\end{matrix}
\right)
= \left(
\begin{matrix}
C_1 e^{2t} + C_2e^{-2t} \\
C_1e^{2t}+5C_2e^{-2t}
\end{matrix}
\right)
\end{equation*}
\end{example}


\begin{example}
In this example, extracted from problem 5.1.32, we are supposed to find a particular solution to the system introduced in the previous example, subject to the initial conditions\footnote{Here we recall the convention discussed during the lecture: lower-case letters are the scalar components of vectors, whereas vectors are indicated by lower-case boldface letters.}
\begin{equation*}
x_1(0)  = 5, \\ x_2(0) = -3.
\end{equation*}
We need to find constants $C_1$ and $C_2$ such that 
\begin{equation*}
\left(
\begin{matrix}
C_1+C_2 \\
C_1+5C_2
\end{matrix}
\right) = \left(
\begin{matrix}
5 \\ 
-3
\end{matrix}
\right)
\end{equation*}
By elimination, we find the solutions $C_1=7$ and $C_2=-2$, thus the final solution is 
\begin{equation*}
\mathbf{x}(t) = \left(
\begin{matrix}
7e^{2t}-2e^{-2t}\\
7e^{2t}-10e^{-2t}
\end{matrix}
\right)
\end{equation*}
\end{example}

\section*{Section 5.2: The Eigenvalue Method for Homogeneous Systems}
In section 5.2 we discuss the method of eigenvalues and eigenvectors to solve systems of linear differential equations. Let us briefly recall such concepts below. 

Given an $n \times n$ matrix $A$, its characteristic polynomial is 
\begin{equation*}
p(r) = \det(A-rI),
\end{equation*}
where $I$ denotes the $n\ times n$ identity matrix. The (possibly complex) roots of this polynomial are called the eigenvalues of A. Given an eigenvalue $r$, non-zero solutions (column-vectors) to the following equation
\begin{equation*}
A\mathbf{v}=r\mathbf{v}
\end{equation*}
are called eigenvectors (relative to $r$). In the easy cases we will deal with here, one should expect to find as many independent eigenvectors as the rank of the matrix, but students should keep in mind that this is not always the case (cf. section 5.5 in our textbook).

\begin{example}
Consider the following system, extracted from problem 5.2.7, 
\begin{equation*}
\mathbf{x}^{'}(t) = \left(
\begin{matrix}
-3 & 4 \\
6 & -5
\end{matrix}
\right) \mathbf{x}(t)
\end{equation*}
The characteristic polynomial of this system is
\begin{equation*}
p(r) = \det \left(
\begin{matrix}
(-3-r) & 4 \\
6 & (-5-r)
\end{matrix}
\right) =r^2+8r-0,
\end{equation*}
whose roots are $r_1=-9$ and $r_2=1$. 

Next let us find the corresponding eigenvectors. The eigenvector equation for $r_1$ is 
\begin{align*}
\left(
\begin{matrix}
-3 & 4 \\
6 & -5
\end{matrix}
\right) \left(
\begin{matrix}
u_1 \\
v_1
\end{matrix} 
\right) & = \left(
\begin{matrix}
-9u_1 \\
-9v_1
\end{matrix}
\right) \\
\left(
\begin{matrix}
-3u_1+4v_1 \\
6u_1 -5v_1
\end{matrix}
\right) & = \left(
\begin{matrix}
-9u_1 \\
-9v_1
\end{matrix}
\right)
\end{align*}
This results in the equation 
\begin{equation*}
6u_1+4v_1 = 0,
\end{equation*}
and the column vector $u_1=-2, v_1=3$ is a solution. By a similar procedure, we find that $u_2=v_2=1$ is yields an eigenvector associated to $r_2 =1$. These are linear independent vectors, so the general solution to the problem is 
\begin{equation*}
x(t) = C_1\left( 
\begin{matrix}
-2 \\
3
\end{matrix}
\right)e^{-9t} + C_2\left(
\begin{matrix}
1 \\
1
\end{matrix}\right)e^t
\end{equation*}
\end{example}

\begin{thebibliography}{0}

\bibitem{EdPeCa} C. Henry Edwards, David E. Penney and David T. Calvis, {\it Differential Equations and Boundary Value Problems: Computing and Modelling}, 5th edition, Pearson, 2014.

\end{thebibliography}
\end{document}


